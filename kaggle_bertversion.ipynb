{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T10:02:56.153316Z","iopub.execute_input":"2021-11-26T10:02:56.153844Z","iopub.status.idle":"2021-11-26T10:02:56.174931Z","shell.execute_reply.started":"2021-11-26T10:02:56.153805Z","shell.execute_reply":"2021-11-26T10:02:56.174141Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import re\ndataset=pd.read_csv(\"/kaggle/input/train-news/train.csv\")\ndataset.columns=['id','content','comment_all','label']\ndataset=dataset.set_index('id')\ntest=pd.read_csv(\"/kaggle/input/train-news/test.csv\")\ntest.columns=['id','content','comment_all']\ntest=test.set_index('id')\ntestset=test\n","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:02:56.176557Z","iopub.execute_input":"2021-11-26T10:02:56.176807Z","iopub.status.idle":"2021-11-26T10:02:57.511483Z","shell.execute_reply.started":"2021-11-26T10:02:56.176774Z","shell.execute_reply":"2021-11-26T10:02:57.510744Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import jieba\ndef clear(text)->str:\n    #print(re.findall('[\\u4E00-\\u9FFF]+|\\d',text))\n    if type(text) is float:return \n    str1=\"\"\n    str2=str1.join(text)\n    y=lambda x:re.findall('[\\u4E00-\\u9FFF]+',x)\n    li=y(str2)\n    for i in range(len(li)):\n        li[i]=list(jieba.cut(li[i]))\n    li2=[]\n    for subli in li:\n        for item in subli:\n            li2.append(item)\n    return li2\ntext='正则365表达\\t式ds匹配/--*测\\t试文字'\na=clear(dataset.loc[9982,'content'])\nb=clear(dataset.loc[9984,'comment_all'])\nc=clear(testset.loc[9979,'content'])\nfor index,row in dataset.iterrows():\n    dataset.at[index,'content']=clear(dataset.at[index,'content'])\n    dataset.at[index,'comment_all']=clear(dataset.at[index,'comment_all'])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:02:57.513084Z","iopub.execute_input":"2021-11-26T10:02:57.513580Z","iopub.status.idle":"2021-11-26T10:04:04.394765Z","shell.execute_reply.started":"2021-11-26T10:02:57.513542Z","shell.execute_reply":"2021-11-26T10:04:04.394049Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:04:04.396691Z","iopub.execute_input":"2021-11-26T10:04:04.396947Z","iopub.status.idle":"2021-11-26T10:04:04.424771Z","shell.execute_reply.started":"2021-11-26T10:04:04.396913Z","shell.execute_reply":"2021-11-26T10:04:04.423984Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset2=[]\nfor index,row in dataset.iterrows():\n    str2=\" \"\n    if dataset.loc[index,'comment_all']is None:\n        dataset2.append(dataset.loc[index,'content'])\n    else:\n        dataset2.append(dataset.loc[index,'content']+dataset.loc[index,'comment_all'])\nfor index,row in testset.iterrows():\n    testset.at[index,'content']=clear(testset.at[index,'content'])\n    testset.at[index,'comment_all']=clear(testset.at[index,'comment_all'])","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:04:04.426224Z","iopub.execute_input":"2021-11-26T10:04:04.426473Z","iopub.status.idle":"2021-11-26T10:04:23.623895Z","shell.execute_reply.started":"2021-11-26T10:04:04.426437Z","shell.execute_reply":"2021-11-26T10:04:23.623193Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset.to_pickle('split_dataset')\ntestset.to_pickle('split_testset')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:04:23.625055Z","iopub.execute_input":"2021-11-26T10:04:23.625346Z","iopub.status.idle":"2021-11-26T10:04:26.089266Z","shell.execute_reply.started":"2021-11-26T10:04:23.625310Z","shell.execute_reply":"2021-11-26T10:04:26.088468Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import pickle\ndataset=open('split_dataset','rb')\ndataset=pickle.load(dataset)\ntestset=open('split_testset','rb')\ntestset=pickle.load(testset)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:04:26.090677Z","iopub.execute_input":"2021-11-26T10:04:26.090966Z","iopub.status.idle":"2021-11-26T10:04:27.900308Z","shell.execute_reply.started":"2021-11-26T10:04:26.090926Z","shell.execute_reply":"2021-11-26T10:04:27.899496Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def label_get(dataset):\n    labelset=[]\n    for index,row in dataset.iterrows():\n        labelset.append(dataset.loc[index,'label'])\n    return labelset\n\nlabelset=label_get(dataset)\ndef pd_li_transform(dataset):\n    dataset_list=[]\n    for index,row in dataset.iterrows():\n        str2=\" \"\n        if dataset.loc[index,'comment_all']is None:\n            dataset_list.append(dataset.loc[index,'content'])\n        else:\n            dataset_list.append(dataset.loc[index,'content']+dataset.loc[index,'comment_all'])\n    return dataset_list\ntestset_list=pd_li_transform(testset)\ndataset_list=pd_li_transform(dataset)\ndef list_deal(dataset,labelset):\n    labelset2=[]\n    dataset2=[]\n    for i in range(len(dataset)):\n        if (dataset[i]!=[]):\n            dataset2.append(dataset[i])\n            labelset2.append(labelset[i])\n    return dataset2,labelset2\ndataset_list,labelset=list_deal(dataset_list,labelset)\ndef list_onehot(labelset):\n    newli=[]\n    for index in labelset:\n        if (index==-1):newli.append([-1.0,0.0,0.0])\n        if (index==0):newli.append([0.0,-1.0,0.0])\n        if (index==1):newli.append([0.0,0.0,-1.0])\n    return newli\ndef list_float(labelset):\n    newli=[]\n    for index in labelset:\n        if (index==-1):newli.append(0.0)\n        if (index==0):newli.append(1.0)\n        if (index==1):newli.append(2.0)\n    return newli\nlabelset3=list_float(labelset)\nlabelset2=list_onehot(labelset)\ndef li_str_transform(dataset_list):\n    dataset2=[]\n    for seq in dataset_list:\n        str1=' '.join(seq)\n        dataset2.append(str1)\n    return dataset2\ndataset_str=li_str_transform(dataset_list)\ntestset_str=li_str_transform(testset_list)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:04:27.901803Z","iopub.execute_input":"2021-11-26T10:04:27.902061Z","iopub.status.idle":"2021-11-26T10:04:34.918782Z","shell.execute_reply.started":"2021-11-26T10:04:27.902022Z","shell.execute_reply":"2021-11-26T10:04:34.917963Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from fastNLP import DataSet\ndata_init=DataSet({'raw_chars':dataset_list,'target':labelset})\ndata_train=data_init[:30000]\ndata_validation=data_init[30001:35000]\ndata_test=DataSet({'raw_chars':testset_list})\nfrom fastNLP import Vocabulary\nvocab=Vocabulary()\nvocab.from_dataset(data_train,field_name='raw_chars',no_create_entry_dataset=[data_validation])\nvocab.index_dataset(data_train,field_name='raw_chars')\nvocab.index_dataset(data_validation,field_name='raw_chars')\nvocab.index_dataset(data_test,field_name='raw_chars')\ntarget_vocab=Vocabulary(padding=None,unknown=None)\ntarget_vocab.from_dataset(data_train,field_name='target')\ntarget_vocab.index_dataset(data_train,field_name='target')\ntarget_vocab.index_dataset(data_validation,field_name='target')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:07:29.450968Z","iopub.execute_input":"2021-11-26T10:07:29.451676Z","iopub.status.idle":"2021-11-26T10:07:48.910848Z","shell.execute_reply.started":"2021-11-26T10:07:29.451640Z","shell.execute_reply":"2021-11-26T10:07:48.910084Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"pip install fastnlp","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:07:09.541995Z","iopub.execute_input":"2021-11-26T10:07:09.542268Z","iopub.status.idle":"2021-11-26T10:07:21.000530Z","shell.execute_reply.started":"2021-11-26T10:07:09.542237Z","shell.execute_reply":"2021-11-26T10:07:20.999609Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data_train","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:04:34.943392Z","iopub.status.idle":"2021-11-26T10:04:34.943929Z","shell.execute_reply.started":"2021-11-26T10:04:34.943694Z","shell.execute_reply":"2021-11-26T10:04:34.943721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.rename_field('raw_chars','words')\ndata_validation.rename_field('raw_chars','words')\ndata_train.set_input('words')\ndata_train.set_target('target')\ndata_validation.set_input('words')\ndata_validation.set_target('target')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:07:48.912556Z","iopub.execute_input":"2021-11-26T10:07:48.912895Z","iopub.status.idle":"2021-11-26T10:07:48.923915Z","shell.execute_reply.started":"2021-11-26T10:07:48.912857Z","shell.execute_reply":"2021-11-26T10:07:48.923065Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(len(data_test))","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:04:34.947846Z","iopub.status.idle":"2021-11-26T10:04:34.948410Z","shell.execute_reply.started":"2021-11-26T10:04:34.948166Z","shell.execute_reply":"2021-11-26T10:04:34.948203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom fastNLP.embeddings import BertEmbedding\nfrom fastNLP import Vocabulary\nembed=BertEmbedding(vocab,model_dir_or_name='cn-wwm', include_cls_sep=True,auto_truncate=True)\nfrom fastNLP.models import BertForSequenceClassification\nmodel = BertForSequenceClassification(embed,num_labels=3)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:09:14.843743Z","iopub.execute_input":"2021-11-26T10:09:14.844128Z","iopub.status.idle":"2021-11-26T10:09:18.651874Z","shell.execute_reply.started":"2021-11-26T10:09:14.844093Z","shell.execute_reply":"2021-11-26T10:09:18.651099Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from fastNLP import Trainer, CrossEntropyLoss, AccuracyMetric, Adam\ndevice = 0 if torch.cuda.is_available() else 'cpu'\nprint(device)\ntrainer = Trainer(data_train, model,\n                  optimizer=Adam(model_params=model.parameters(), lr=2e-5),\n                  loss=CrossEntropyLoss(), device=device,\n                  batch_size=8,dev_data=data_validation,\n                  metrics=AccuracyMetric(), n_epochs=5, print_every=1)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:11:20.422440Z","iopub.execute_input":"2021-11-26T10:11:20.422875Z","iopub.status.idle":"2021-11-26T12:24:52.667873Z","shell.execute_reply.started":"2021-11-26T10:11:20.422835Z","shell.execute_reply":"2021-11-26T12:24:52.667208Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_predict(model,data,device):\n    submission=pd.DataFrame(columns=['Prediction'])\n#    submission = pd.DataFrame(columns=['ID','Prediction'])\n    submission=[]\n    for i in range(len(data)):\n    #for i in range(5):\n#         print(data.words[i])\n        if (i%100==0):print(f\"第{i}次预测完成。\")\n        model=model.to(device)\n        tensor = torch.tensor(data['raw_chars'][i]).to(device)\n        pred = model.predict(tensor.view(1,-1))\n        prob = pred['pred'].cpu().numpy()[0]\n        submission.append(prob)\n    return submission\nsubmission=batch_predict(model,data_test,device)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-26T12:37:10.255015Z","iopub.execute_input":"2021-11-26T12:37:10.255284Z","iopub.status.idle":"2021-11-26T12:40:16.724132Z","shell.execute_reply.started":"2021-11-26T12:37:10.255252Z","shell.execute_reply":"2021-11-26T12:40:16.723442Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"submission2=[]\nfor i in range(len(submission)):\n    if(submission[i]==2):submission2.append(0)\n    elif(submission[i]==0):submission2.append(1)\n    elif(submission[i]==1):submission2.append(-1)\n    else:submission2.append(submission[i])\n\nnp.savetxt('/kaggle/working/bert.txt',submission2,fmt='%d',delimiter='\\n')\nprint(\"OK\")","metadata":{"execution":{"iopub.status.busy":"2021-11-26T12:46:54.662581Z","iopub.execute_input":"2021-11-26T12:46:54.662839Z","iopub.status.idle":"2021-11-26T12:46:54.701620Z","shell.execute_reply.started":"2021-11-26T12:46:54.662809Z","shell.execute_reply":"2021-11-26T12:46:54.700839Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}